{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nimport itertools\nimport sklearn\nimport scipy\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport squarify\nimport matplotlib.ticker as ticker\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima_model import ARMA\nfrom statsmodels.tsa.stattools import adfuller\nimport statsmodels.api as sm\nfrom scipy.spatial.distance import euclidean\nimport sys\nfrom sklearn.preprocessing import MinMaxScaler\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/crimes-in-boston/crime.csv',encoding='latin-1')\n\ndf.drop(\"INCIDENT_NUMBER\",axis=1, inplace=True) \n\ndf[[\"DATE\",\"TIME\"]]=df['OCCURRED_ON_DATE'].str.split(\" \",expand=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot line chart\ndef lineplt(x,y,xlabel,ylabel,title,size,tick_spacing):\n    fig,ax=plt.subplots(figsize = size)\n    plt.plot(x,y)\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n    plt.xlabel(xlabel,fontsize = 15)\n    plt.ylabel(ylabel,fontsize = 15)\n    plt.title(title,fontsize = 20)\n    plt.show()\n\n# Create 2 columes DateFrame\ndef createdf(c1,d1,c2,d2):\n    dic = {c1:d1,c2:d2}\n    df = pd.DataFrame(dic)\n    return df\n\n# Plot histogram\ndef plthis(d,bin, title):\n    plt.figure(figsize=(10,8))\n    plt.hist(d, bins=bin)\n    plt.title(title, fontsize = 20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Put Date and Count into a new Dataframe\nc = createdf(\"Date\",df[\"DATE\"].value_counts().index,\"Count\",df[\"DATE\"].value_counts())\n\n# c is the total number of crimes per day\nc.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 The distribution of the Counts of Crimes by date"},{"metadata":{"trusted":true},"cell_type":"code","source":"plthis(c[\"Count\"],50, \"Crimes Count Distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('skewness is ' + str(c['Count'].skew()))\nprint('kurtosis is ' + str(c['Count'].kurt()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bin=pd.cut(c[\"Count\"],50)\nfre= createdf(\"Bin\",bin.value_counts().index,\"Count\",bin.value_counts())\nfre_sort = fre.sort_values(by = \"Bin\", ascending = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1.1 Shapiro-Wilk test\n(For N > 5000 the W test statistic is accurate but the p-value may not be.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"(_,p) = scipy.stats.shapiro(fre_sort[\"Count\"])\nprint('p-value is ' + str(p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1.2 Kolmogorov-Smirnov test"},{"metadata":{"trusted":true},"cell_type":"code","source":"(_,p) = scipy.stats.kstest(fre_sort[\"Count\"],'norm')\nprint('p-value is ' + str(p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the result of this two tests, we can see that the p value is very small, much smaller than 5%. So we can conclude that the distribution is **Significantly different** from normal distribution under 95% confidence."},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Distribution of Crimes by Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"c=c.sort_values(by=\"Date\",ascending = True)\nlineplt(c[\"Date\"],c[\"Count\"],\"Date\",\"Count\",\"Crimes by Time\",(20,15),80)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the chart above, we can see there are many peaks and troughs and they shows a kind of pattern like \"sin\" function. I'm going to use some numbers and charts to describe the pattern in detail."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,16))\nax1 = fig.add_subplot(411)\nfig = plot_acf(c[\"Count\"],lags=200,ax=ax1)\nplt.title('Autocorrelation Lag=200')\nax2 = fig.add_subplot(412)\nfig = plot_pacf(c[\"Count\"],lags=200,ax=ax2)\nplt.title('Partial Autocorrelation Lag=200')\nax3 = fig.add_subplot(413)\nfig = plot_acf(c[\"Count\"],lags=15,ax=ax3)\nplt.title('Autocorrelation Lag=15')\nax4 = fig.add_subplot(414)\nfig = plot_pacf(c[\"Count\"],lags=15,ax=ax4)\nplt.title('Partial Autocorrelation Lag=15')\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None,\n                wspace=None, hspace=0.5)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking at the Autocorrelation and Partical Autocorrelation (lag = 200 and lag = 15), we can conclude that:\n\n(1) From lag 1 to lag 100, the correlation is positive and from lag 100 to lag 200, the correlation is negative. So around every 100 days, the correlation will be reversed. This can describe the \"Sin\" shape.\n\n(2) When we make the lag shorter, we can see more details about the correlation. The partical correlations are significant when lag 1, lag 6 and lag 7. So we can conclude that the crimes are correlated with yesterday and the same day in last week."},{"metadata":{"trusted":true},"cell_type":"code","source":"res = sm.tsa.seasonal_decompose(c['Count'],freq=12,model=\"additive\")\n# # original = res\ntrend = res.trend\nseasonal = res.seasonal\nresidual = res.resid\n\nfig,ax=plt.subplots(figsize = (20,15))\nax1 = fig.add_subplot(411)\nax1.xaxis.set_major_locator(ticker.MultipleLocator(80))\nax1.plot(c['Count'], label='Original')\nax1.legend(loc='best')\nax2 = fig.add_subplot(412)\nax2.xaxis.set_major_locator(ticker.MultipleLocator(80))\nax2.plot(trend, label='Trend')\nax2.legend(loc='best')\nax3 = fig.add_subplot(413)\nax3.xaxis.set_major_locator(ticker.MultipleLocator(10))\nax3.plot(seasonal[:100],label='Seasonality')\nax3.legend(loc='best')\nax4 = fig.add_subplot(414)\nax4.xaxis.set_major_locator(ticker.MultipleLocator(80))\nax4.plot(residual, label='Residuals')\nax4.legend(loc='best')\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After seasonal decomposing, we can have a clear view of the pattern of the distribution of crimes. But there is one problem. When we try to plot the data, the chart will have different shape if we use different scales. For example, if the range of y axis is between 0~300, then the variation will be very clear, and we can see if there is a trend. But if the range is between 0~3000, then the variation will be unclear and the shape of the date could be a straight line. So we need to value the stationarity of the data becasue I'm planning to use ARIMA model."},{"metadata":{},"cell_type":"markdown","source":"# 2.2.1 ADF Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_stationarity(series,mlag = 365, lag = None,):\n    print('ADF Test Result')\n    res = adfuller(series, maxlag = mlag, autolag = lag)\n    output = pd.Series(res[0:4],index = ['Test Statistic', 'p value', 'used lag', 'Number of observations used'])\n    for key, value in res[4].items():\n        output['Critical Value ' + key] = value\n    print(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(c['Count'],lag = 'AIC')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The report shows that, the \"used lag\" is 34 and p value is 0.19. So we can conclude, in the range of 34 days, we can **NOT Reject** the null hypotheses which is the time series is non-stationary."},{"metadata":{},"cell_type":"markdown","source":"## 2.3 ARIMA Model"},{"metadata":{},"cell_type":"markdown","source":"Because the data is not stationary, we need to do first difference to the date in order to make it stationary."},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = c.copy()\nd1['Count'] = d1['Count'].diff(1)\nd1 = d1.dropna()\nlineplt(d1[\"Date\"],d1[\"Count\"],\"Date\",\"Count\",\"Crimes by Time\",(20,15),80)\nprint('Average= '+str(d1['Count'].mean()))\nprint('Std= ' + str(d1['Count'].std()))\nprint('SE= ' + str(d1['Count'].std()/math.sqrt(len(d1))))\nprint(test_stationarity(d1['Count'],lag = 'AIC'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the fist differencing, the chat looks much more stationary and the ADF test shows a pretty low p value. So we can rejct H0. The Time series is stational after first differencing."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_2 = plt.figure(figsize=(16,8))\nax1_2 = fig_2.add_subplot(211)\nfig_2 = plot_acf(d1[\"Count\"],lags=15,ax=ax1_2)\nax2_2 = fig_2.add_subplot(212)\nfig_2 = plot_pacf(d1[\"Count\"],lags=15,ax=ax2_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Autocorrelation and Partial Autocorrelation charts are not very perfet. We can see there is a seasonal pattern every 7 days. \n\nWe will deal with it later. But let's build the ARIMA model first"},{"metadata":{"trusted":true},"cell_type":"code","source":"timeseries = c['Count']\np,d,q = (4,1,2)\narma_mod = ARMA(timeseries,(p,d,q)).fit()\nsummary = (arma_mod.summary2(alpha=.05, float_format=\"%.8f\"))\nprint(summary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_data = arma_mod.predict(start='2016-07-01', end='2017-07-01', dynamic = False)\ntimeseries.index = pd.DatetimeIndex(timeseries.index)\nfig, ax = plt.subplots(figsize=(20, 15))\nax = timeseries.plot(ax=ax)\npredict_data.plot(ax=ax)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}